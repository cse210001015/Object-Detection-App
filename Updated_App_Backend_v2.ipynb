{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cse210001015/Object-Detection-App/blob/main/Updated_App_Backend_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi nest-asyncio pyngrok uvicorn websockets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D62dwAes3S_8",
        "outputId": "a783b237-82e7-4bb6-b61a-55a77188e0b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fastapi\n",
            "  Downloading fastapi-0.95.1-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.9/dist-packages (1.5.6)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-6.0.0.tar.gz (681 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m681.2/681.2 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.21.1-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets\n",
            "  Downloading websockets-11.0.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m129.7/129.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /usr/local/lib/python3.9/dist-packages (from fastapi) (1.10.7)\n",
            "Collecting starlette<0.27.0,>=0.26.1\n",
            "  Downloading starlette-0.26.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from pyngrok) (6.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.9/dist-packages (from uvicorn) (8.1.3)\n",
            "Collecting h11>=0.8\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2->fastapi) (4.5.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.9/dist-packages (from starlette<0.27.0,>=0.26.1->fastapi) (3.6.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.9/dist-packages (from anyio<5,>=3.4.0->starlette<0.27.0,>=0.26.1->fastapi) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.9/dist-packages (from anyio<5,>=3.4.0->starlette<0.27.0,>=0.26.1->fastapi) (1.3.0)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-6.0.0-py3-none-any.whl size=19879 sha256=d9e6ea35c62cb10b9a499045085fd7b6faac2e5bcadb7af6ed9ba441108a02ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/49/9c/44b13823eb256a3b4dff34b972f7a3c7d9910bfef269e59bd7\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: websockets, pyngrok, h11, uvicorn, starlette, fastapi\n",
            "Successfully installed fastapi-0.95.1 h11-0.14.0 pyngrok-6.0.0 starlette-0.26.1 uvicorn-0.21.1 websockets-11.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ux9UEERr3YtT",
        "outputId": "bd1c25ad-9fd9-4404-82d6-2798b87204a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUbtQv5S4dl-",
        "outputId": "23aa349d-889f-4f85-f269-55e35cb902d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/WongKinYiu/yolov7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckw57RMS4wh7",
        "outputId": "bae1a64b-cb4f-4829-aa28-760128eab1e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov7'...\n",
            "remote: Enumerating objects: 1139, done.\u001b[K\n",
            "remote: Total 1139 (delta 0), reused 0 (delta 0), pack-reused 1139\u001b[K\n",
            "Receiving objects: 100% (1139/1139), 70.41 MiB | 17.36 MiB/s, done.\n",
            "Resolving deltas: 100% (488/488), done.\n",
            "Updating files: 100% (104/104), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd yolov7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTF5cazJ42kV",
        "outputId": "d8408595-316c-4b25-a376-84099c791b91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/yolov7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSzvsPEg466l",
        "outputId": "02b5aae1-9ebd-4c49-9a68-42de636b59c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-22 23:54:42--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230422%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230422T235442Z&X-Amz-Expires=300&X-Amz-Signature=e72ee435723cfb64034382daf52c9868bc858818a8fa632f6d54e65d8795ed56&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-04-22 23:54:42--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230422%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230422T235442Z&X-Amz-Expires=300&X-Amz-Signature=e72ee435723cfb64034382daf52c9868bc858818a8fa632f6d54e65d8795ed56&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75587165 (72M) [application/octet-stream]\n",
            "Saving to: ‚Äòyolov7.pt‚Äô\n",
            "\n",
            "yolov7.pt           100%[===================>]  72.08M  48.5MB/s    in 1.5s    \n",
            "\n",
            "2023-04-22 23:54:44 (48.5 MB/s) - ‚Äòyolov7.pt‚Äô saved [75587165/75587165]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KF-l_D1J6A5b",
        "outputId": "2d9b3d8f-dbb9-4651-810f-de004e93d97f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def detect(path):\n",
        "  !python detect.py --weights yolov7.pt --conf 0.25 --img-size 640 --source '{path}' --name images"
      ],
      "metadata": {
        "id": "vmB0wME98iCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "def draw_bboxes(path,predictions):\n",
        "  image=cv2.imread(path)\n",
        "  for bbox in predictions:\n",
        "    x0=bbox['x']\n",
        "    y0=bbox['y']\n",
        "    x1=bbox['x']+bbox['width']\n",
        "    y1=bbox['y']+bbox['height']\n",
        "    color=(0,255,0)\n",
        "    thickness=2\n",
        "\n",
        "    image=cv2.rectangle(image,(x0,y0),(x1,y1),color,thickness)\n",
        "\n",
        "    font=cv2.FONT_HERSHEY_PLAIN\n",
        "    org=(x0,y0)\n",
        "    fontScale=1\n",
        "    color=(0,0,0)\n",
        "    thickness=2\n",
        "\n",
        "    image=cv2.putText(image,bbox['class'],org,font,fontScale,color,thickness,cv2.LINE_AA)"
      ],
      "metadata": {
        "id": "AJKRTyyXutPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "def detect_img(path,model):\n",
        "  image = Image.open(path)\n",
        "  transform = transforms.Compose([transforms.PILToTensor()])\n",
        "  img_tensor = transform(image)\n",
        "  with torch.no_grad():\n",
        "    predictions=model(img_tensor)\n",
        "    draw_bboxes(path,predictions)"
      ],
      "metadata": {
        "id": "0XK9r20TpHd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def detect_video(path,model):\n",
        "  shutil.rmtree('output')\n",
        "  capture=cv2.VideoCapture(path)\n",
        "  no_of_frames=0\n",
        "  fps = video.get(cv2.CAP_PROP_FPS) #cv2 version above 3.\n",
        "\n",
        "  while(True):\n",
        "    success,frame=capture.read()\n",
        "    if success:\n",
        "      cv2.imwrite(f'output/frame_{no_of_frames}.jpg',frame)\n",
        "      detect_img(f'output/frame_{no_of_frames}.jpg',model)\n",
        "    else:\n",
        "      break\n",
        "    no_of_frames+=1\n",
        "  capture.release()\n",
        "\n",
        "  images=[img for img in os.listdir('output')]\n",
        "  frame = cv2.imread(os.path.join('output', images[0]))\n",
        "  height, width, layers = frame.shape\n",
        "\n",
        "  video = cv2.VideoWriter(path, 0, fps, (width,height))\n",
        "\n",
        "  for image in images:\n",
        "    video.write(cv2.imread(os.path.join('output', image)))\n",
        "\n",
        "  cv2.destroyAllWindows()\n",
        "  video.release()"
      ],
      "metadata": {
        "id": "jeYHUB9RqbEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEfhACVr26PZ",
        "outputId": "f78d4512-7b1c-4136-9b84-e2f809afe064"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-04-23T07:22:18+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n",
            "INFO:     Started server process [689]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://6648-35-197-18-59.ngrok.io\n",
            "INFO:     185.107.56.45:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     185.107.56.45:0 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
            "INFO:     95.142.107.4:0 - \"GET / HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     ('103.159.214.186', 0) - \"WebSocket /ws\" [accepted]\n",
            "INFO:     connection open\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125700\n",
            "Complete 125700\n",
            "Namespace(weights=['yolov7.pt'], source='video.mp4', img_size=640, conf_thres=0.25, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='images', exist_ok=False, no_trace=False)\n",
            "YOLOR üöÄ v0.1-122-g3b41c2c torch 2.0.0+cu118 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "Model Summary: 306 layers, 36905341 parameters, 6652669 gradients\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "video 1/1 (1/35) /content/drive/MyDrive/yolov7/video.mp4: 1 person, Done. (15.9ms) Inference, (35.4ms) NMS\n",
            "video 1/1 (2/35) /content/drive/MyDrive/yolov7/video.mp4: 1 person, Done. (15.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (3/35) /content/drive/MyDrive/yolov7/video.mp4: 1 person, Done. (15.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (4/35) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (15.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (5/35) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (15.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (6/35) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (15.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (7/35) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (15.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (8/35) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (15.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (9/35) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (15.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (10/35) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (15.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (11/35) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (15.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (12/35) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (15.8ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (13/35) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (11.5ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (14/35) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (9.5ms) Inference, (0.9ms) NMS\n",
            "video 1/1 (15/35) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (9.5ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (16/35) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (9.5ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (17/35) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (9.5ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (18/35) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (9.5ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (19/35) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (9.5ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (20/35) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (9.5ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (21/35) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (9.4ms) Inference, (0.9ms) NMS\n",
            "video 1/1 (22/35) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (9.4ms) Inference, (0.9ms) NMS\n",
            "video 1/1 (23/35) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (9.4ms) Inference, (0.9ms) NMS\n",
            "video 1/1 (24/35) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (9.4ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (25/35) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (13.1ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (26/35) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (9.4ms) Inference, (0.9ms) NMS\n",
            "video 1/1 (27/35) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (9.2ms) Inference, (0.9ms) NMS\n",
            "video 1/1 (28/35) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (8.0ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (29/35) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (8.0ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (30/35) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (8.0ms) Inference, (0.9ms) NMS\n",
            "video 1/1 (31/35) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (7.9ms) Inference, (0.9ms) NMS\n",
            "video 1/1 (32/35) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (7.9ms) Inference, (0.9ms) NMS\n",
            "video 1/1 (33/35) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (8.5ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (34/35) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (8.1ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (35/35) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (8.1ms) Inference, (0.9ms) NMS\n",
            "Done. (0.865s)\n",
            "184295\n",
            "185032\n",
            "Complete 185032\n",
            "Namespace(weights=['yolov7.pt'], source='video.mp4', img_size=640, conf_thres=0.25, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='images', exist_ok=False, no_trace=False)\n",
            "YOLOR üöÄ v0.1-122-g3b41c2c torch 2.0.0+cu118 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "Model Summary: 306 layers, 36905341 parameters, 6652669 gradients\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "video 1/1 (1/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (14.7ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (2/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (14.6ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (3/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (14.6ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (4/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (14.7ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (5/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (14.6ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (6/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (11.6ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (7/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (11.6ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (8/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (11.6ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (9/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (11.6ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (10/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (11.6ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (11/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (11.6ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (12/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (11.6ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (13/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (11.6ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (14/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (11.6ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (15/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (11.6ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (16/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (11.6ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (17/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (11.6ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (18/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (8.0ms) Inference, (0.9ms) NMS\n",
            "video 1/1 (19/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (7.5ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (20/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (7.5ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (21/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (7.5ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (22/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (7.5ms) Inference, (1.5ms) NMS\n",
            "video 1/1 (23/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (7.6ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (24/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (7.6ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (25/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (7.5ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (26/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (7.5ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (27/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (7.5ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (28/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (7.5ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (29/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (7.5ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (30/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (7.5ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (31/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (7.5ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (32/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (7.5ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (33/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (7.5ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (34/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (7.3ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (35/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (7.0ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (36/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (7.0ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (37/37) /content/drive/MyDrive/yolov7/video.mp4: 2 persons, Done. (7.1ms) Inference, (1.0ms) NMS\n",
            "Done. (0.768s)\n",
            "306479\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/uvicorn/protocols/websockets/websockets_impl.py\", line 254, in run_asgi\n",
            "    result = await self.app(self.scope, self.asgi_receive, self.asgi_send)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/uvicorn/middleware/proxy_headers.py\", line 78, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/fastapi/applications.py\", line 276, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/starlette/applications.py\", line 122, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/starlette/middleware/errors.py\", line 149, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/starlette/middleware/exceptions.py\", line 79, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/starlette/middleware/exceptions.py\", line 68, in __call__\n",
            "    await self.app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/fastapi/middleware/asyncexitstack.py\", line 21, in __call__\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/starlette/routing.py\", line 718, in __call__\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/starlette/routing.py\", line 341, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/starlette/routing.py\", line 82, in app\n",
            "    await func(session)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/fastapi/routing.py\", line 289, in app\n",
            "    await dependant.call(**values)\n",
            "  File \"<ipython-input-10-cc000f94b09a>\", line 42, in websocket\n",
            "    message=await websocket.receive_text()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/starlette/websockets.py\", line 113, in receive_text\n",
            "    self._raise_on_disconnect(message)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/starlette/websockets.py\", line 105, in _raise_on_disconnect\n",
            "    raise WebSocketDisconnect(message[\"code\"])\n",
            "starlette.websockets.WebSocketDisconnect: 1006\n",
            "INFO:     connection closed\n",
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [689]\n"
          ]
        }
      ],
      "source": [
        "from fastapi import FastAPI\n",
        "from fastapi.websockets import WebSocket\n",
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "import base64\n",
        "from pydantic import BaseModel\n",
        "import shutil\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "class File(BaseModel):\n",
        "    imgsource:str\n",
        "\n",
        "@app.get('/')\n",
        "async def home():\n",
        "  return \"Hello World\"\n",
        "\n",
        "@app.post('/')\n",
        "async def process_image(file:File):\n",
        "    image_data=base64.b64decode(file.imgsource)\n",
        "    path='img.png'\n",
        "    f=open(path,'wb')\n",
        "    f.write(image_data)\n",
        "    f.close()\n",
        "    try:\n",
        "      shutil.rmtree('/content/drive/MyDrive/yolov7/runs/detect/images')\n",
        "    except:\n",
        "      pass\n",
        "    detect(path)  #model=torch.load(model_path)   detect_img(path,model)\n",
        "\n",
        "    image_path='/content/drive/MyDrive/yolov7/runs/detect/images/img.png'\n",
        "    img_file=open(image_path,'rb')\n",
        "    detected_image_base64=base64.b64encode(img_file.read())\n",
        "    return detected_image_base64\n",
        "\n",
        "@app.websocket('/ws')\n",
        "async def websocket(websocket:WebSocket):\n",
        "  await websocket.accept()\n",
        "  await websocket.send_text(\"Connected\")\n",
        "  video_file=''\n",
        "  path='video.mp4'\n",
        "  video_path='/content/drive/MyDrive/yolov7/runs/detect/images/video.mp4'\n",
        "  while True:\n",
        "    message=await websocket.receive_text()\n",
        "    if message==\"End\":\n",
        "\n",
        "      print(\"Complete\",len(video_file))\n",
        "      f=open(path,'wb')\n",
        "      video_file=base64.b64decode(video_file)\n",
        "      f.write(video_file)\n",
        "      video_file=''\n",
        "      f.close()\n",
        "      try:\n",
        "        shutil.rmtree('/content/drive/MyDrive/yolov7/runs/detect/images')\n",
        "      except:\n",
        "        pass\n",
        "      detect(path)  #model=torch.load(model_path)   detect_video(path,model)\n",
        "\n",
        "      detected_video_file=open(video_path,'rb')\n",
        "      detected_video_base64=str(base64.b64encode(detected_video_file.read()))\n",
        "      print(len(detected_video_base64))\n",
        "\n",
        "      while(len(detected_video_base64)>931388):\n",
        "        s=detected_video_base64[0:931388]\n",
        "        await websocket.send_text(s)\n",
        "        detected_video_base64=detected_video_base64[931388:]\n",
        "\n",
        "      if(len(detected_video_base64)>0):\n",
        "        await websocket.send_text(detected_video_base64)\n",
        "      \n",
        "      await websocket.send_text(\"End\")\n",
        "\n",
        "    else:\n",
        "      video_file+=message\n",
        "      print(len(message))\n",
        "  await websocket.close()\n",
        "\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8000)"
      ]
    }
  ]
}